source("C:/Users/laure/Documents/urban_malaria/MRMT/Shiny_app/functions.R")
# packges to use
list_of_packages <- c("stringr","ggplot2", "dplyr", "purrr", "haven", "tidyverse",
"readxl", "patchwork", "tidyr", "factoextra", "MASS", "broom",
"glm2", "viridis")
read_install_pacakges <- function(packages = list_of_packages
){
new_packages <- packages[!(list_of_packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new_packages)
return(sapply(list_of_packages, require, character.only = TRUE))
}
list_of_packages <- c("stringr","ggplot2", "dplyr", "purrr", "haven", "tidyverse",
"readxl", "patchwork", "tidyr", "factoextra", "MASS", "broom",
"glm2", "viridis")
read_install_pacakges <- function(packages = list_of_packages
){
new_packages <- packages[!(list_of_packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new_packages)
return(sapply(list_of_packages, require, character.only = TRUE))
}
read_install_pacakges()
list_of_packages <- c("sf", "vroom", "stringr", "dplyr",
"tidyr", "reshape2","ggplot2","ggiraph", "RColorBrewer"
"gridExtra","shinythemes", "viridis", "shinyjs", "readxl",
read_install_pacakges <- function(packages = list_of_packages
){
new_packages <- packages[!(list_of_packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new_packages)
return(sapply(list_of_packages, require, character.only = TRUE))
}
read_install_pacakges()
list_of_packages
list_of_packages <- c("sf", "vroom", "stringr", "dplyr",
"tidyr", "reshape2","ggplot2","ggiraph", "RColorBrewer"
"gridExtra","shinythemes", "viridis", "shinyjs", "readxl",
list_of_packages <- c("sf", "vroom", "stringr", "dplyr",
"tidyr", "reshape2","ggplot2","ggiraph", "RColorBrewer",
"gridExtra","shinythemes", "viridis", "shinyjs", "readxl",
"shinydashboard", "shinyBS", "rlang", "shiny", "bslib", "plotly",
"spdep", "stringdist","DiagrammeR", "glue", "DT")
read_install_pacakges <- function(packages = list_of_packages
){
new_packages <- packages[!(list_of_packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new_packages)
return(sapply(list_of_packages, require, character.only = TRUE))
}
read_install_pacakges()
source("C:/Users/laure/Documents/urban_malaria/MRMT/Shiny_app/functions.R")
runApp('Shiny_app')
shiny::runApp('Shiny_app')
runApp('Shiny_app')
rank = 1:30
rank %in% 5:6
runApp('Shiny_app')
?raster::extract
# Load necessary libraries
library(tidytext)
library(dplyr)
library(ggplot2)
# Example data: sentences to analyze
sentences <- data.frame(
id = 1:5,
text = c(
"I love the new features, they are amazing!",
"The app crashes frequently and is frustrating.",
"Support has been helpful and prompt.",
"Not bad, but could be improved.",
"This is the worst experience I've ever had!"
)
)
# Tokenize sentences into words
tokenized_words <- sentences %>%
unnest_tokens(word, text)
# Load Bing sentiment lexicon
bing_lexicon <- get_sentiments("bing")
# Join tokenized words with the Bing lexicon
sentiment_scores <- tokenized_words %>%
inner_join(bing_lexicon, by = "word") %>%
count(id, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_score = positive - negative)
# Join tokenized words with the Bing lexicon
sentiment_scores <- tokenized_words %>%
inner_join(bing_lexicon, by = "word") %>%
count(id, sentiment) %>%
dplyr::pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_score = positive - negative)
# Join tokenized words with the Bing lexicon
sentiment_scores <- tokenized_words %>%
inner_join(bing_lexicon, by = "word") %>%
count(id, sentiment) %>%
tidyverse::pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment_score = positive - negative)
shiny::runApp('Shiny_app')
runApp('Shiny_app')
shiny::runApp('Shiny_app')
runApp('Shiny_app')
source("C:/Users/laure/Documents/urban_malaria/MRMT/analysis_scripts/generate_manual.R")
install.packages("quarto")
source("C:/Users/laure/Documents/urban_malaria/MRMT/analysis_scripts/generate_manual.R")
library(tidytext)
library(sentimentr)
library(syuzhet)
library(textTinyR)
# Sample text
text <- c("I love this product! But the service was terrible. sad happy excited bad")
# Dictionary-based sentiment (syuzhet)
syuzhet_score <- get_sentiment(text, method = "syuzhet")
syuzhet_score
# Contextual sentiment (sentimentr)
sentimentr_score <- sentiment(text)
sentimentr_score
sentimentr_score
# Contextual sentiment (sentimentr)
sentimentr_score <- sentiment(text) %>%
mutate(class = ifelse(sentiment > 0, "positive",
ifelse(sentiment < 0, "negative", "nuetral")))
library(dplyr)
# Contextual sentiment (sentimentr)
sentimentr_score <- sentiment(text) %>%
mutate(class = ifelse(sentiment > 0, "positive",
ifelse(sentiment < 0, "negative", "nuetral")))
sentimentr_score
data <- data %>%
# Sentiment analysis using TextBlob lexicon in R
# Get detailed sentiment data
# Average polarity for each response
mutate(Sentiment_Details = map(Response, ~ sentimentr::sentiment(.x)),
Polarity = map_dbl(Sentiment_Details, ~ mean(.x$sentiment)))
source("scripts/load_paths.R")
getwd()
source("analysis_scripts/scripts/load_paths.R")
responses <- read.csv( "data/openeded.csv")
data <- tibble(Response = responses$openended)
data <- data %>%
# Sentiment analysis using TextBlob lexicon in R
# Get detailed sentiment data
# Average polarity for each response
mutate(Sentiment_Details = map(Response, ~ sentimentr::sentiment(.x)),
Polarity = map_dbl(Sentiment_Details, ~ mean(.x$sentiment)))
data <- data %>%
# Sentiment analysis using TextBlob lexicon in R
# Get detailed sentiment data
# Average polarity for each response
mutate(Sentiment_Details = map(Response, ~ sentimentr::sentiment(.x)),
Polarity = map_dbl(Sentiment_Details, ~ mean(.x$sentiment))) %>%
mutate(Sentiment = case_when(
Polarity > 0 ~ "Positive",
Polarity < 0 ~ "Negative",
TRUE ~ "Neutral"
))
responses
responses <- read.csv( "data/openeded.csv")
